---
title: "Impact of Subgroup Misclassification on Detecting Heterogeneous Treatment Effects in *Staphylococcus aureus* Bacteremia: A Simulation Study"
author: "Fergus Hamilton"
format: 
  html:
    self-contained: true
    toc: true
    code-fold: true
    code-summary: "Show code"
editor: visual
execute: 
  echo: true
  warning: false
  message: false
---

```{r setup, include=FALSE}
# Load necessary packages
pacman::p_load(
  tidyverse, 
  broom, 
  ggdist, 
  gt,          # For nice tables
  patchwork    # For combining plots
)

# Set theme for plots
theme_set(theme_minimal() + theme(legend.position = "bottom"))

# Source the simulation functions using a relative path
source("../code/functions/functions.R")

# Set seed for overall reproducibility
set.seed(20240423)
```

## Abstract

*(Placeholder for Abstract: Briefly summarize background, methods, key findings, and conclusion after results are generated)*

## Introduction

*Staphylococcus aureus* bacteremia (SAB) is a serious infection characterized by significant clinical heterogeneity in patient presentation, disease course, and outcomes. Recent research by Swets, Russell, et al. (Clinical Infectious Diseases, 2024) identified five distinct clinical subphenotypes within SAB using latent class analysis on data from observational and trial cohorts (Edinburgh, ARREST, SAFO).

Crucially, a secondary analysis of the ARREST trial (Adjunctive Rifampicin for *S. aureus* Bacteraemia) suggested differential treatment effects of adjunctive rifampicin across these subphenotypes. Specifically, rifampicin was associated with increased 84-day mortality in subphenotype B (Nosocomial IV catheter-associated SAB; OR 18.8) and improved microbiologic outcomes in subphenotype C (Community-acquired metastatic SAB; OR 0.17).

This finding raises a critical question for both clinical trial design and potential future stratified treatment approaches: If such treatment effect heterogeneity exists, how accurately must patients be classified into these subphenotypes to reliably detect these differences and avoid misleading conclusions? Misclassification is inevitable with any diagnostic or predictive tool, and understanding its impact is essential.

This simulation study aims to address this question by:

1.  Estimating the sample sizes required to detect the subgroup-specific treatment effects observed by Russell et al. with adequate statistical power, assuming perfect patient classification.
2.  Quantifying the impact of varying levels of classification accuracy on statistical power, estimation bias (Mean Squared Error), and the probability of estimating effects in the wrong direction for both subgroup-specific and overall treatment effects.

## Methods

### Simulation Model

We developed a simulation model based on the functions defined in `code/functions/functions.R`. The core steps for each simulation run are:

1.  **Data Generation (`simulate_trial_data`):** Simulate individual patient data for a hypothetical two-arm (treatment vs. control) trial of size `n`. Patients are assigned a 'true' subgroup (A-E) based on specified frequencies. Treatment is assigned randomly (50/50). An outcome ('success', e.g., survival at 84 days) is generated for each patient based on their true subgroup, treatment assignment, the subgroup-specific baseline event probability (`p0`), and the subgroup-specific treatment effect (odds ratio, `or_vector`).
2.  **Misclassification:** An 'assigned' subgroup is determined for each patient. With probability `accuracy`, the assigned subgroup matches the true subgroup. With probability `1 - accuracy`, the patient is randomly assigned to *any* subgroup (A-E) based on the overall subgroup frequencies.
3.  **Effect Estimation (`estimate_effect_misclassify`):** Logistic regression (`glm(success ~ treatment, family = binomial)`) is performed separately for patients within each *assigned* subgroup (A-E) and for the overall cohort. The estimated log odds ratio (beta), standard error (se), and p-value for the treatment effect are extracted for each assigned subgroup and overall.

### Parameterization

The simulation parameters were chosen to reflect the findings from the Russell et al. analysis of the ARREST trial data, specifically focusing on the 84-day mortality outcome with adjunctive rifampicin vs. placebo.

-   **Treatment Effects (Odds Ratios):** The 'true' underlying ORs for the treatment (rifampicin) effect on 84-day mortality compared to control (placebo) within each subgroup were set based on the point estimates reported:
    -   `or_vector <- c(A = 1.0, B = 18.8, C = 0.79, D = 1.4, E = 0.3)`
    -   Note: The large OR in subgroup B (18.8) suggests potential harm, while the OR \< 1 in E (0.3) suggests benefit. Other ORs are closer to 1.
-   **Subgroup Frequencies:** The proportions of patients in each subgroup were based on the distribution observed in the ARREST placebo arm (n=388):
    -   `freq_vector <- c(A = 60/388, B = 52/388, C = 138/388, D = 69/388, E = 69/388)`
    -   Approximately: A=15.5%, B=13.4%, C=35.6%, D=17.8%, E=17.8%
-   **Baseline Event Rates (p0):** The baseline probability of the outcome (death by 84 days) in the *control* group for each subgroup was estimated from the ARREST placebo arm:
    -   `p0_vector <- c(A = 7/60, B = 0/52, C = 11/138, D = 11/69, E = 1/69)`
    -   `p0_vector_adjusted <- c(A = 7/60, B = 0.001, C = 11/138, D = 11/69, E = 1/69)` \# Adjusted for zero

### Simulation Scenarios

-   **Aim 1 (Sample Size Estimation):**\
    Classification `accuracy` fixed at 1.0; total sample sizes (`n`) varied over `sample_sizes`; `n_reps = 1000` each; compute power per subgroup (Bonferroni‐corrected).
-   **Aim 2 (Impact of Accuracy):**\
    Total sample size fixed (`n = 5000`); classification `accuracy` varied over `accuracy_levels`; `n_reps = 1000`; compute power, bias, MSE, and wrong‐direction rate per subgroup and overall.

### Analysis

Simulation results were aggregated across repetitions; summarized with descriptive tables (`gt`) and plots (`ggplot2`).

## Results

```{r define_parameters}
# Define core parameters
or_mortality       <- c(A = 1.0, B = 18.8, C = 0.79, D = 1.4, E = 0.3)
freq_arrest        <- c(A = 60/388, B = 52/388, C = 138/388, D = 69/388, E = 69/388)
p0_arrest_raw      <- c(A = 7/60, B = 0/52, C = 11/138, D = 11/69, E = 1/69)
p0_arrest_adjusted <- p0_arrest_raw; p0_arrest_adjusted["B"] <- 0.001
n_reps_global      <- 10
sample_sizes       <- c(500, 1000, 2000, 3000, 5000, 7500, 10000)
accuracy_levels    <- seq(0.5, 1.0, by = 0.05)
n_fixed_aim2       <- 5000
```

### Aim 1: Sample Size Requirements

```{r aim1_simulations, cache=TRUE}
results_aim1 <- map_dfr(sample_sizes, ~replicate_sims(
  or_vector  = or_mortality,
  freq_vector = freq_arrest,
  p0_vector  = p0_arrest_adjusted,
  n          = .x,
  accuracy   = 1.0,
  n_reps     = n_reps_global,
  seed       = 1
), .id = "size_id") %>%
  mutate(n_total = sample_sizes[as.numeric(size_id)])
power_aim1 <- results_aim1 %>%
  filter(group != "Overall") %>%
  group_by(n_total, group) %>%
  summarise(power = mean(pval < 0.05 / 5), .groups = "drop")
```

```{r aim1_plot_power}
ggplot(power_aim1, aes(x = n_total, y = power, color = group)) +
  geom_line() + geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed") +
  scale_x_continuous(breaks = sample_sizes) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Aim 1: Statistical Power vs Sample Size",
    x = "Total Sample Size",
    y = "Power",
    color = "Subgroup"
  )
```

### Aim 2: Impact of Classification Accuracy

```{r aim2_simulations, cache=TRUE}
results_aim2 <- map_dfr(accuracy_levels, ~replicate_sims(
  or_vector  = or_mortality,
  freq_vector = freq_arrest,
  p0_vector  = p0_arrest_adjusted,
  n          = n_fixed_aim2,
  accuracy   = .x,
  n_reps     = n_reps_global,
  seed       = 2
), .id = "acc_id") %>%
  mutate(accuracy = accuracy_levels[as.numeric(acc_id)])
summary_aim2 <- results_aim2 %>%
  group_by(accuracy, group) %>%
  summarise(
    power     = if_else(group == "Overall", mean(pval < 0.05), mean(pval < 0.05 / 5)),
    bias      = mean(beta - true_beta),
    mse       = mean(mse),
    wrong_dir = mean(sign(beta) != sign(true_beta)) * 100,
    .groups   = "drop"
  )
```

```{r aim2_plot_power}
ggplot(summary_aim2, aes(x = accuracy, y = power, color = group)) +
  geom_line() + geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed") +
  labs(
    title = paste("Aim 2: Power vs Accuracy (N =", n_fixed_aim2, ")"),
    x     = "Classification Accuracy",
    y     = "Power",
    color = "Subgroup/Overall"
  )
```

```{r aim2_plot_bias}
ggplot(summary_aim2 %>% filter(group != "Overall"), aes(x = accuracy, y = bias, color = group)) +
  geom_line() + geom_point() +
  facet_wrap(~ group, scales = "free_y") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = paste("Aim 2: Estimation Bias vs Accuracy (N =", n_fixed_aim2, ")"),
    x     = "Classification Accuracy",
    y     = "Bias (log OR)",
    color = "Subgroup/Overall"
  )
```

```{r aim2_plot_wrong_direction}
ggplot(summary_aim2 %>% filter(group != "Overall"), aes(x = accuracy, y = wrong_dir, color = group)) +
  geom_line() + geom_point() +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  labs(
    title = paste("Aim 2: Wrong Direction % vs Accuracy (N =", n_fixed_aim2, ")"),
    x     = "Classification Accuracy",
    y     = "Wrong Direction (%)",
    color = "Subgroup"
  )
```

## Supplementary: Realistic Effects

```{r setup_realistic, include=FALSE}
or_realistic <- c(A = 1.0, B = 2.0, C = 0.7, D = 1.2, E = 0.8)
```

### Supplementary Aim 1: Power vs. Sample Size

```{r aim1_simulations_realistic, cache=TRUE}
results_aim1_real <- map_dfr(sample_sizes, ~replicate_sims(
  or_vector   = or_realistic,
  freq_vector = freq_arrest,
  n           = .x,
  p0_vector   = p0_arrest_adjusted,
  accuracy    = 1.0,
  n_reps      = n_reps_global,
  seed        = 4
), .id = "size_id") %>%
  mutate(n_total = sample_sizes[as.numeric(size_id)])
power_aim1_real <- results_aim1_real %>%
  filter(group != "Overall") %>%
  group_by(n_total, group) %>%
  summarise(power = mean(pval < 0.05 / 5), .groups = "drop")
```

```{r aim1_plot_power_realistic}
ggplot(power_aim1_real, aes(x = n_total, y = power, color = group)) +
  geom_line() + geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed") +
  scale_x_continuous(breaks = sample_sizes) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Supplementary: Power vs. Sample Size (Realistic ORs)",
    x     = "Total Sample Size",
    y     = "Power",
    color = "Subgroup"
  )
```

### Supplementary Aim 2: Power vs. Accuracy

```{r aim2_simulations_realistic, cache=TRUE}
results_aim2_real <- map_dfr(accuracy_levels, ~replicate_sims(
  or_vector   = or_realistic,
  freq_vector = freq_arrest,
  n           = n_fixed_aim2,
  p0_vector   = p0_arrest_adjusted,
  accuracy    = .x,
  n_reps      = n_reps_global,
  seed        = 5
), .id = "acc_id") %>%
  mutate(accuracy = accuracy_levels[as.numeric(acc_id)])
summary_aim2_real <- results_aim2_real %>%
  group_by(accuracy, group) %>%
  summarise(
    power     = if_else(group == "Overall", mean(pval < 0.05), mean(pval < 0.05 / 5)),
    bias      = mean(beta - true_beta),
    wrong_dir = mean(sign(beta) != sign(true_beta)) * 100,
    .groups   = "drop"
  )
```

```{r aim2_plot_power_realistic}
ggplot(summary_aim2_real, aes(x = accuracy, y = power, color = group)) +
  geom_line() + geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed") +
  labs(
    title = paste("Supplementary: Power vs Accuracy (Realistic; n =", n_fixed_aim2, ")"),
    x     = "Classification Accuracy",
    y     = "Power",
    color = "Subgroup/Overall"
  )
```

```{r aim2_plot_bias_realistic}
ggplot(summary_aim2_real %>% filter(group != "Overall"), aes(x = accuracy, y = bias, color = group)) +
  geom_line() + geom_point() +
  facet_wrap(~ group, scales = "free_y") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = paste("Supplementary: Estimation Bias vs Accuracy (Realistic; n =", n_fixed_aim2, ")"),
    x     = "Classification Accuracy",
    y     = "Bias (log OR)",
    color = "Subgroup/Overall"
  )
```

```{r aim2_plot_wrong_realistic}
ggplot(summary_aim2_real %>% filter(group != "Overall"), aes(x = accuracy, y = wrong_dir, color = group)) +
  geom_line() + geom_point() +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  labs(
    title = paste("Supplementary: Wrong Direction % vs Accuracy (Realistic; n =", n_fixed_aim2, ")"),
    x     = "Classification Accuracy",
    y     = "Wrong Direction (%)",
    color = "Subgroup"
  )
```

# Visualization Bias 2: ARREST

```{r visualization_bias2, echo=FALSE}
ggplot(results_aim2 %>% mutate(bias = beta - true_beta), aes(x = factor(accuracy), y = bias, fill = group)) +
  geom_boxplot(position = position_dodge(width = 0.7)) +
  facet_wrap(~ group, scales = "free_y") +
  geom_hline(data = tibble(group = names(or_mortality), true_beta = log(or_mortality)),
             aes(yintercept = true_beta), linetype = "dashed", color = "black") +
  labs(
    title = paste("Bias Distribution vs Accuracy (ARREST; n =", n_fixed_aim2, ")"),
    x = "Classification Accuracy",
    y = "Bias (log OR)"
  )
```

# Visualization Bias 2: Realistic

```{r visualization_bias2_realistic, echo=FALSE}
ggplot(results_aim2_real %>% mutate(bias = beta - true_beta), aes(x = factor(accuracy), y = bias, fill = group)) +
  geom_boxplot(position = position_dodge(width = 0.7)) +
  facet_wrap(~ group, scales = "free_y") +
  geom_hline(data = tibble(group = names(or_realistic), true_beta = log(or_realistic)),
             aes(yintercept = true_beta), linetype = "dashed", color = "black") +
  labs(
    title = paste("Bias Distribution vs Accuracy (Realistic; n =", n_fixed_aim2, ")"),
    x = "Classification Accuracy",
    y = "Bias (log OR)"
  )
```

## Discussion

This simulation study demonstrates the significant challenges in detecting heterogeneous treatment effects in the presence of subgroup misclassification, using parameters derived from a real-world *S. aureus* bacteremia trial. Aim 1 highlights that even with perfect classification, substantial sample sizes are required to achieve adequate power for subgroup-specific effects, particularly for less prevalent subgroups or those with smaller effect sizes.

Aim 2 quantifies the detrimental impact of misclassification accuracy. As accuracy decreases, statistical power diminishes, bias in effect estimates increases (generally towards the null), and the probability of estimating effects in the wrong direction rises. This underscores the critical importance of highly accurate subgroup classification methods for reliable detection and estimation of heterogeneous treatment effects. Subgroups with true null effects are particularly susceptible to high rates of "wrong direction" findings under misclassification.

## Conclusion

This simulation study demonstrates that accurate subgroup classification is paramount for reliably detecting heterogeneous treatment effects in *S. aureus* bacteremia. Even moderate levels of misclassification can substantially reduce statistical power, bias effect estimates, and increase the risk of incorrect conclusions about the direction of treatment effects within subgroups. These findings emphasize the need for robust subgroup identification methods and careful consideration of misclassification when designing and interpreting stratified medicine studies.

## References

-   Swets, M. C., Russell, C. D., et al. (2024). Clinical Subphenotypes of Staphylococcus aureus Bacteremia. *Clinical Infectious Diseases*, ciaes338. https://doi.org/10.1093/cid/ciae338
-   *(Add other relevant references)*